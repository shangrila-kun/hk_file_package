# 算法复杂性分析的一个简单介绍

Dionysis“dionyziz”Zindros < 

dionyziz@gmail.com

 >

- [英语](http://discrete.gr/complexity/?en)
- [Ελληνικά](http://discrete.gr/complexity/?el)
- [македонски](http://discrete.gr/complexity/?mk)
- [西班牙语](http://discrete.gr/complexity/?es)
- [帮助翻译](mailto:dionyziz@gmail.com)

## 介绍

很多编程人员今天制作了一些最酷，最实用的软件，比如我们在互联网上看到的或每天使用的很多东西，都没有理论计算机科学背景。他们仍然非常棒，有创意的程序员，我们感谢他们为他们构建的东西。

然而，理论计算机科学有它的用途和应用，并且可以证明是相当实用的。在本文中，针对那些了解他们艺术但没有任何理论计算机科学背景的程序员，我将介绍计算机科学最实用的工具之一：大O符号和算法复杂性分析。作为一个在计算机科学学术环境中工作和在行业中构建生产级软件的人，这是我发现的在实践中真正有用的工具之一，所以我希望在阅读本文后，您可以将其应用于您自己的代码中以使其更好。阅读本文后，您应该能够理解计算机科学家使用的所有常见术语，如“大O”，“渐近行为”和“最坏情况分析”。

本文也针对来自希腊的初中和高中学生或其他任何国际参加[国际信息学奥林匹克](http://en.wikipedia.org/wiki/International_Olympiad_in_Informatics)竞赛，学生算法竞赛或其他类似比赛。因此，它没有任何数学上的先决条件，并且会给你所需的背景，以便继续深入理解背后的理论并研究算法。作为曾经在这些学生竞赛中竞争的人，我强烈建议您仔细阅读这些介绍性材料并尝试完全理解它，因为在学习算法和学习更先进的技术时，这将是必要的。

我相信这篇文章对那些没有太多理论计算机科学经验的行业程序员是有帮助的（事实上，一些最鼓舞人心的软件工程师从未上过大学）。但是因为它也适用于学生，有时听起来有点像教科书。另外，本文中的一些主题对您来说可能看起来太明显了; 例如，你可能在你高中时看过他们。如果你觉得你理解他们，你可以跳过他们。其他部分进一步深入并略为理论化，因为参加本次比赛的学生需要比普通从业人员更多地了解理论算法。但是这些东西仍然很好知道，而且不是很难遵循，所以这可能是值得你花时间的。

在整篇文章中，您将找到各种指针，将您链接到有趣的材料，这些材料经常超出讨论主题的范围。如果你是一位行业程序员，那么你很可能已经熟悉了这些概念。如果您是参加比赛的初级学生，那么通过以下链接可以获得关于计算机科学或软件工程领域的其他领域的线索，这些领域您可能还没有探索过哪些方面可以扩大您的兴趣。

大O符号和算法复杂性分析是很多行业程序员和初级学生都很难理解，恐惧或完全避免为无用的。但这并不像起初看起来那么艰难或理论化。算法复杂性只是一种正式测量程序或算法运行速度的方式，所以它确实非常实用。我们首先来激励一下这个话题。

![半条命2中的人工智能角色截图](http://discrete.gr/complexity/images/halflife2.jpg)**图1**：视频游戏中的人工智能特征使用算法来避免在虚拟世界中导航时遇到障碍

## 动机

我们已经知道有一些工具可以测量程序的运行速度。有些程序称为*分析器*，它以毫秒为单位测量运行时间，并可帮助我们通过发现瓶颈来优化代码。虽然这是一个有用的工具，但它与算法复杂性无关。算法复杂性是为了在思想层次上比较两种算法而设计的 - 忽略低级细节，例如实现编程语言，算法运行的硬件或给定CPU的指令集。我们想根据它们的内容来比较算法：计算某些东西的想法。计数毫秒不会帮助我们。用[汇编](http://en.wikipedia.org/wiki/Assembly_language)等低级编程语言编写的错误算法很有可能比使用[Python](http://www.python.org/)或[Ruby](http://www.ruby-lang.org/en/)等高级编程语言编写的优秀算法运行速度快得多。所以现在是时候定义一个“更好的算法”了。

由于算法是只执行计算的程序，而不是计算机经常执行的其他事情，例如网络任务或用户输入和输出，因此复杂性分析允许我们衡量程序执行计算时的速度。纯粹*计算*的操作示例包括数值[浮点运算](http://en.wikipedia.org/wiki/Floating_point)，如加法和乘法; 在适合RAM的数据库中搜索给定值; 确定人工智能角色在视频游戏中将要经历的路径，以便他们只需在虚拟世界内走近一小段距离（**见图1**）; 或者在字符串上运行[正则表达式](http://www.regular-expressions.info/)模式匹配。显然，计算在计算机程序中无处不在。

复杂性分析也是一个工具，可以让我们解释随着输入变大，算法的表现如何。如果我们给它一个不同的输入，算法将如何表现？如果我们的算法需要1秒才能运行1000个输入，那么如果我将输入大小加倍，它的行为如何？它会以同样快的速度，快一半还是四倍的速度运行？在实际编程中，这很重要，因为它可以让我们预测当输入数据变大时我们的算法将如何表现。例如，如果我们已经为一个适用于1000个用户并测量其运行时间的Web应用程序制定了算法，使用算法复杂性分析，我们可以很好地了解一旦我们获得2000个用户会发生什么。对于算法竞赛，复杂性分析让我们了解我们的代码将运行多长时间用于测试程序正确性的最大测试用例。因此，如果我们测量了我们的程序对于一个小输入的行为，我们可以很好地了解它对于较大输入的行为。让我们从一个简单的例子开始：查找数组中的最大元素。

## 计数指令

在本文中，我将为这些示例使用各种编程语言。但是，如果您不知道某种编程语言，请不要失望。既然你知道编程，即使你不熟悉所选择的编程语言，你也应该可以毫无问题地阅读这些示例，因为它们很简单，我不会使用任何深奥的语言特性。如果您是参加算法竞赛的学生，您很可能会使用[C ++](http://www.cplusplus.com/doc/tutorial/)，所以您应该没有问题。在这种情况下，我建议使用C ++进行练习练习。

数组中的最大元素可以用一段简单的代码来查找，比如这段[JavaScript](http://www.quirksmode.org/js/intro.html)代码。给定一个大小为n的输入数组A：

`var` `M = A[ 0 ];`

 

`for` `( ``var` `i = 0; i < n; ++i ) {`

`if` `( A[ i ] >= M ) {`

`M = A[ i ];`

`}`

`}`

现在，我们要做的第一件事就是计算这段代码执行多少条*基本指令*。我们只会这样做一次，并且在我们发展理论时不需要这么做，所以我们这么做的时候请耐心等待。当我们分析这段代码时，我们想把它分解成简单的指令; 那些可以由CPU直接执行的或者接近于此的东西。我们假设我们的处理器可以按照每条指令执行以下操作：

- 为变量分配一个值
- 查找数组中特定元素的值
- 比较两个值
- 增加一个值
- 基本的算术运算，如加法和乘法

我们将假设分支（条件已经被评估之后的代码之间的选择`if`和`else`部分代码`if`）立即发生并且不会计数这些指令。在上面的代码中，第一行代码是：

`var` `M = A[ 0 ];`

这需要2条指令：一条用于查找A [0]和一条用于将值赋给M（我们假设n总是至少为1）。无论n的值如何，算法总是需要这两条指令。该`for`环路初始化代码也必须始终运行。这给了我们两个更多的指示; 作业和比较：

`i = 0;`

`i < n;`

这些将在第一次`for`循环迭代之前运行。在每次`for`循环迭代之后，我们还需要两条指令才能运行，增加i和比较来检查我们是否会留在循环中：

`++i;`

`i < n;`

所以，如果我们忽略循环体，这个算法需要的指令数是4 + 2n。也就是说，`for`循环开始时有4条指令，每个迭代结束时有2条指令，我们有n条指令。我们现在可以定义一个数学函数f（n），给定一个n给出了算法需要的指令数量。对于空`for`体，我们有f（n）= 4 + 2n。

## 最坏情况分析

现在，看看`for`body，我们有一个数组查找操作和一个总是会发生的比较：

`if` `( A[ i ] >= M ) { ...`

那里有两条说明。但是`if`实体可能会运行或者可能不运行，这取决于数组的值实际是什么。如果碰巧是这样`A[ i ] >= M`，那么我们将运行这两个附加指令 - 一个数组查找和一个赋值：

`M = A[ i ]`

但是现在我们不能很容易地定义f（n），因为我们的指令数量并不仅仅依赖于n而且还取决于我们的输入。例如，对于`A = [ 1, 2, 3, 4 ]`算法将需要更多的指令比`A = [ 4, 3, 2, 1 ]`。在分析算法时，我们经常考虑最坏的情况。我们的算法会发生什么最坏的情况？我们的算法何时需要大部分指令才能完成？在这种情况下，当我们有一个数组按递增顺序时，如`A = [ 1, 2, 3, 4 ]`。在这种情况下，M需要每次更换，以便产生最多的指示。计算机科学家有一个奇特的名字，他们称之为*最坏情况分析*; 这只不过是考虑我们最不幸的情况而已。所以，在最坏的情况下，我们有4条指令在`for`主体内运行，所以我们有f（n）= 4 + 2n + 4n = 6n + 4。这个函数f给出了问题的大小n，在最坏的情况下将需要的指示。

## 渐近行为

鉴于这样的功能，我们对算法的速度有一个很好的想法。但是，正如我所承诺的那样，我们不需要完成计算指令的枯燥任务。此外，每种编程语言语句所需的实际CPU指令的数量取决于编程语言的编译器和可用的CPU指令集（例如，您的PC上是AMD还是Intel Pentium，或者您的Playstation上是MIPS处理器2），我们说我们会忽略这一点。我们现在将通过一个“过滤器”来运行我们的“f”函数，这将帮助我们摆脱那些计算机科学家们不愿意忽略的细节。

在我们的函数6n + 4中，我们有两个项：6n和4.在复杂性分析中，我们只关心指令计数函数随着程序输入（n）变大而发生了什么。这与以前的“最坏情况”行为的想法是一致的：我们对如何处理糟糕的算法表现感兴趣; 当遇到挑战时要努力工作。请注意，比较算法时这非常有用。如果一个算法为大输入跳过另一个算法，那么当给出更简单，更小的输入时，更快的算法保持更快可能是正确的。**从我们正在考虑的条款中，我们将放弃所有增长缓慢的条款，只保留随着n变大而快速增长的条款。**显然4仍然是一个4作为Ñ越来越大，但6n越来越大，因此对于更大的问题，它往往越来越重要。因此，我们要做的第一件事是放下4并保持函数f（n）= 6n。

这是有道理的，如果你考虑它，因为4只是一个“初始化常量”。不同的编程语言可能需要不同的时间来设置。例如，Java需要一些时间来初始化其[虚拟机](http://en.wikipedia.org/wiki/Java_virtual_machine)。由于我们忽略了编程语言的差异，因此忽略此值才有意义。

我们将忽略的第二件事是n前面的常数乘法器，所以我们的函数将变成f（n）= n。正如你所看到的，这很简化了很多事情。同样，如果我们考虑编译语言的编译方式，那么放弃这个乘法常量是有道理的。一种语言中的“数组查询”语句可以用不同的编程语言编译成不同的指令。例如，在C中，做`A[ i ]`不包括检查我在声明的数组大小内，而在[Pascal中](http://en.wikipedia.org/wiki/Pascal_(programming_language))它做。所以，下面的Pascal代码：

`M := A[ i ]`

在C中相当于以下内容：

`if` `( i >= 0 && i < n ) {`

`M = A[ i ];`

`}`

因此，期望不同的编程语言在计算他们的指令时会产生不同的因素。在我们的示例中，我们正在使用一个愚蠢的编译器来忽略可能的优化，Pascal需要3条指令来访问每个数组，而不是1条C指令所需的指令。忽略这个因素是忽略了特定编程语言和编译器之间的差异，只是分析了算法本身的思想。

如上所述，“放弃所有因素”和“保持最大增长期限”的过滤器就是我们所说的*渐近行为*。所以f（n）= 2n + 8的渐近行为由函数f（n）= n描述。从数学上讲，我们在这里说的是我们对函数f的极限感兴趣，因为n趋于无穷大; 但是如果你不明白这句话的正式含义，别担心，因为这是你所需要知道的。（在一个侧面说明中，在严格的数学设置中，我们将无法将常数降低到极限;但出于计算机科学的目的，我们希望这样做是出于上述原因。）让我们来看几个例子熟悉这个概念。

![三次函数，蓝色，克服了线性函数，在n = 45之后以红色显示](http://discrete.gr/complexity/images/cubic-vs-linear.png)**图2**：用蓝色绘制的n 3函数变得比1999n函数大，在n = 45之后用红色绘制。在那之后，它永远保持较大。

让我们通过删除常量因子并保持增长最快的项来找到以下示例函数的渐近行为。

1. f（n）= 5n + 12给出f（n）= n。

   通过使用与上述完全相同的推理。

2. f（n）= 109给出f（n）= 1。

   我们放弃了乘法器109 * 1，但是我们仍然必须在此放置1来指示此函数具有非零值。

3. f（n）= n 2 + 3n + 112给出f（n）= n 2

   在这里，对于足够大的n ，n 2增长大于3n，所以我们保持这一点。

4. f（n）= n 3 + 1999n + 1337给出f（n）= n 3

   尽管n前面的因子非常大，但我们仍然可以找到足够大的n以使n 3大于1999n。由于我们对非常大的n值的行为感兴趣，我们只保留n 3（**见图2**）。

5. f（n）= n + ![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)给出f（n）= n

   这是因为n增长得比![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)我们增加n更快。

你可以自己尝试下面的例子：

### 练习1

1. f（n）= n 6 + 3n
2. f（n）= 2 n + 12
3. f（n）= 3 n + 2 n
4. f（n）= n n + n

（写下你的结果;解决方案在下面给出）

如果您遇到以上问题之一，请插入一些较大的n，然后查看哪一项更大。很简单，是吧？

## 复杂

所以这告诉我们的是，因为我们可以放弃所有这些装饰常量，所以很容易判断程序的指令计数函数的渐近行为。事实上，任何没有任何循环的程序都会有f（n）= 1，因为它需要的指令数量只是一个常数（除非它使用递归;见下文）。任何具有从1到n的单循环的程序都将具有f（n）= n，因为它将在循环之前执行恒定数量的指令，在循环之后执行恒定数量的指令以及在循环之后执行恒定数量的指令全部运行n次的循环。

现在应该比计算单个指令容易得多，也没有那么繁琐，所以让我们来看看几个例子来熟悉这个。以下[PHP](http://php.net/)程序检查大小为n的数组A中是否存在特定值：

`<?php`

`$exists` `= false;`

`for` `( ``$i` `= 0; ``$i` `< n; ++``$i` `) {`

`if` `( ``$A``[ ``$i` `] == ``$value` `) {`

`$exists` `= true;`

`break``;`

`}`

`}`

`?>`

这种在数组内搜索值的方法称为*线性搜索*。这是一个合理的名称，因为这个程序有f（n）= n（我们将在下一节中准确定义“线性”的含义）。您可能会注意到，这里有一个“break”语句，即使经过一次迭代，程序也可能会尽快终止。但是请记住，我们对最坏的情况感兴趣，对于这个程序来说，这个程序是为了使数组A不包含这个值。所以我们仍然有f（n）= n。

### 练习2

系统地分析上述PHP程序在最坏的情况下需要的n个指令来寻找f（n），类似于我们如何分析我们的第一个Javascript程序。然后验证，渐近地，我们有f（n）= n。

让我们看看一个Python程序，它将两个数组元素一起添加到一起，以产生一个和它存储在另一个变量中的和：

`v ``=` `a[ ``0` `] ``+` `a[ ``1` `]`

这里我们有一个固定数量的指令，所以我们有f（n）= 1。

C ++中的以下程序检查一个名为A的大小为n的向量（一个花哨的数组）是否包含相同的两个值：

`bool` `duplicate = ``false``;`

`for` `( ``int` `i = 0; i < n; ++i ) {`

`for` `( ``int` `j = 0; j < n; ++j ) {`

`if` `( i != j && A[ i ] == A[ j ] ) {`

`duplicate = ``true``;`

`break``;`

`}`

`}`

`if` `( duplicate ) {`

`break``;`

`}`

`}`

因为在这里我们有两个嵌套的循环，所以我们将有一个渐近行为，由f（n）= n 2描述。

**经验法则**：可以通过计算程序的嵌套循环来分析简单程序。在n项上的单个循环产生f（n）= n。循环内的循环产生f（n）= n 2。循环内循环内的循环产生f（n）= n 3。

如果我们有一个程序在一个循环中调用一个函数，并且我们知道被调用函数执行的指令的数量，那么很容易确定整个程序的指令数量。的确，我们来看看这个C例子：

`int` `i;`

`for` `( i = 0; i < n; ++i ) {`

`f( n );`

`}`

如果我们知道这`f( n )`是一个完全执行n条指令的函数，那么我们就可以知道整个程序的指令数是渐近的n 2，因为函数正好被调用n次。

**经验法则**：给定一系列顺序循环，其中最慢的循环决定程序的渐近行为。两个嵌套循环后跟一个单一循环与嵌套循环单独渐近地相同，因为嵌套循环*支配*简单循环。

现在，让我们切换到计算机科学家使用的奇特符号。当我们逐渐计算出确切的这种f时，我们会说我们的程序是Θ（f（n））。例如，上述程序是Θ（1），Θ（n 2）和Θ（n 2）） 分别。Θ（n）发音为“theta of n”。有时候我们说f（n）是对包括常量的指令进行计数的原函数，它是Θ（某物）。例如，我们可以说f（n）= 2n是一个函数，它是Θ（n） - 这里没有什么新东西。我们也可以写出2n∈Θ（n），它的读音为“two n是n的theta”。不要对这个表示法感到困惑：所有的意思是，如果我们已经计算出了一个程序需要的指令的数量，那么这个算法的渐近行为就用n来描述，我们通过删除常量。鉴于这种表示法，以下是一些真实的数学表述：

1. n 6 + 3n∈Θ（n 6）
2. 2 n +12∈Θ（2 n）
3. 3 Ñ + 2 Ñ ∈Θ（3 Ñ）
4. n n + n∈Θ（n n）

顺便说一下，如果您从上面解决了练习1，这些就是您应该找到的答案。

**我们称这个函数，也就是我们在Θ（这里）中放置了什么，算法的时间复杂度或复杂度。**所以具有Θ（n）的算法具有复杂度n。由于它们经常出现，所以我们也有Θ（1），Θ（n），Θ（n 2）和Θ（log（n））的特殊名称。我们说Θ（1）算法是一个*常数时间算法*，Θ（n）是*线性的*，Θ（n 2）是*二次的*，Θ（log（n））是*对数的*（如果不知道什么对数 - 我们会在一分钟内达成）。

**经验法则**：具有较大Θ的程序比具有较小Θ的程序运行得慢。

![一个隐藏在视频游戏中的曲面的例子](http://discrete.gr/complexity/images/hidden-surface.jpg)**图3**：位于黄点的玩家不会看到阴影区域。将世界分成小片段，并按距离球员的距离排序是解决可见性问题的一种方法。

## 大O符号

现在，有时候确实很难像上面那样精确地确定算法的行为，特别是对于更复杂的示例。但是，我们可以说，我们的算法的行为永远不会超过一定的界限。这将使我们的生活更加轻松，因为我们不必指定算法的运行速度，即使忽略了以前的方式。我们所要做的就是找到一定的界限。用一个例子很容易解释这一点。

计算机科学家用于教学算法的着名问题是*排序问题*。在排序问题中，给出了大小为n的数组A（听起来很熟悉？），并且我们被要求编写一个排序该数组的程序。这个问题很有意思，因为这是实际系统中的一个实际问题。例如，文件资源管理器需要按名称对其显示的文件进行排序，以便用户轻松导航它们。或者，作为另一个例子，视频游戏可能需要基于它们在虚拟世界内与玩家眼睛的距离来对世界中显示的3D对象进行排序，以便确定什么是可见的和什么不是，称为[可见性问题的](http://en.wikipedia.org/wiki/Hidden_surface_determination)东西（**见图3******）。最接近玩家的物体是那些可见的物体，而那些更接近玩家的物体可能被它们前面的物体隐藏。排序也很有趣，因为有很多算法可以解决它，其中有些算法比其他算法更糟。定义和解释也是一个容易的问题。那么我们来编写一个排序数组的代码。

这是一种在Ruby中实现数组排序的低效方法。（当然，Ruby支持使用内置函数对数组进行排序，您应该使用这些函数，而且这些函数肯定比我们在这里看到的速度更快，但是这里仅用于说明目的。）

`b = []`

`n.times ``do`

`m = a[ ``0` `]`

`mi = ``0`

`a.each_with_index ``do` `|element, i|`

`if` `element < m`

`m = element`

`mi = i`

`end`

`end`

`a.delete_at( mi )`

`b << m`

`end`

这种方法被称为[选择排序](http://en.wikipedia.org/wiki/Selection_sort)。它发现我们数组的最小值（数组表示为a，而最小值表示为m，mi是它的索引），将它放在新数组的末尾（在我们的情况b中），并将其从原始数组。然后它找到我们原始数组的剩余值之间的最小值，将其附加到我们的新数组中，以便它现在包含两个元素，并将其从原始数组中移除。它会继续这个过程，直到所有项目都从原始项目中删除并插入到新数组中，这意味着数组已被排序。在这个例子中，我们可以看到我们有两个嵌套循环。外部循环运行n次，并且内部循环为数组a的每个元素运行一次。虽然数组a最初有n个项目，但我们在每次迭代中删除一个数组项目。因此，内循环在外循环的第一次迭代期间重复n次，然后是`n - 1`次数，然后是`n - 2`次数等，直到外循环的最后一次迭代为止，在此期间它只运行一次。

评估这个程序的复杂性有点困难，因为我们必须找出总和1 + 2 + ... +（n-1）+ n。但是我们肯定能为它找到一个“上限”。也就是说，我们可以改变我们的程序（你可以在你的想法中做到这一点，而不是在实际的代码中），让它**变得**比现在**更糟糕**，然后找到我们衍生的新程序的复杂性。如果我们能够找到我们构建的更糟糕的程序的复杂性，那么我们知道我们原来的程序是最坏的，或者更好的。这样，如果我们发现对于我们改变的程序来说相当好的复杂性，这比我们原来的更糟糕，我们可以知道我们的原始程序也会有相当不错的复杂性 - 或者与我们改变的程序一样好，或者甚至更好。

现在让我们想想如何编辑这个示例程序，以便更容易地找出它的复杂性。但让我们记住，我们只能使情况变得更糟，也就是让它接受更多的指示，以便我们的估计对我们原来的计划有意义。显然，我们可以改变程序的内部循环，使其始终重复n次，而不是重复次数。其中一些重复将是无用的，但它将帮助我们分析所得算法的复杂性。如果我们做这个简单的改变，那么我们构造的新算法显然是Θ（n 2），因为我们有两个嵌套循环，每个循环重复n次。如果是这样，我们说原始算法是O（n 2）。O（n 2）的读音是“n的平方大哦”。这说的是我们的程序渐近地不比n 2差。它甚至可能比这更好，或者它可能与此相同。顺便说一句，如果我们的程序确实是Θ（n 2），我们仍然可以说它是O（n 2）。为了帮助你认识到这一点，设想改变原来的程序的方式不会改变太多，但仍会使程序变得更糟，例如在程序开始时添加无意义的指令。这样做会通过一个简单的常量来改变指令计数功能，在渐近行为时忽略它。所以一个Θ（n 2）的程序也是O（n 2）。

但是一个O（n 2）的程序可能不是Θ（n 2）。例如，除了O（n）之外，任何Θ（n）的程序也是O（n 2）。如果我们想象一个Θ（n）程序是一个`for`重复n次的简单循环，我们可以通过将它包装在另一个`for`重复n次的循环中来使它变得更糟，从而产生一个程序f（n）= n 2。为了概括这一点，当b比a更差时，任何Θ（a）的程序都是O（b）。请注意，我们对该程序的更改不需要给我们一个实际上有意义或等同于我们原始程序的程序。对于给定的n，它只需要执行比原始指令更多的指令。我们用它来计算指令，而不是真正解决我们的问题。

所以，说我们的程序是O（n 2）是安全的：我们分析了我们的算法，我们发现它永远不会比n 2差。但事实上它可能是n 2。这给我们一个很好的估计我们的程序运行速度。让我们通过几个例子来帮助您熟悉这种新的符号。

### 练习3

找出以下哪些是真的：

1. Θ（n）算法是O（n）
2. Θ（n）算法是O（n 2）
3. Θ（n 2）算法是O（n 3）
4. Θ（n）算法是O（1）
5. AO（1）算法是Θ（1）
6. AO（n）算法是Θ（1）

### 解

1. 我们知道这是真的，因为我们的原始程序是Θ（n）。我们可以在不改变程序的情况下实现O（n）。
2. 由于n 2比n更糟，这是真的。
3. 由于n 3比n 2差，这是真的。
4. 因为1并不比n差，所以这是错误的。如果一个程序渐渐接受n条指令（线性指令数），我们不能让它变得更糟，并且它只需要1条指令（恒定数量的指令）。
5. 这是真实的，因为这两个复杂性是相同的。
6. 根据算法的不同，这可能会也可能不会。在一般情况下，这是错误的。如果一个算法是Θ（1），那么它肯定是O（n）。但是，如果它是O（n），那么它可能不是Θ（1）。例如，Θ（n）算法是O（n）但不是Θ（1）。

### 练习4

使用算术级数和来证明上面的程序不仅是O（n 2），还有Θ（n 2）。如果您不知道算术级数是多少，请在[维基百科](http://en.wikipedia.org/wiki/1_%2B_2_%2B_3_%2B_4_%2B_%E2%80%A6)上查看- 这很容易。

由于算法的O复杂性给出了算法的实际复杂度的*上限*，而Θ给出了算法的实际复杂度，我们有时会说Θ给了我们一个*紧密的界限*。如果我们知道我们已经发现复杂度不太紧的话，我们也可以用小写的o来表示这个。例如，如果算法是Θ（n），那么它的紧密复杂度是n。那么这个算法既是O（n）又是O（n 2）。由于该算法是Θ（n），O（n）边界是紧密的。但是O（n 2）的界限并不紧密，所以我们可以写出算法是o（n 2）），这是发音“n平方小”，以说明我们知道我们的约束不紧。如果我们能够找到我们算法的紧密边界，那么会更好，因为这些给我们提供了有关我们的算法如何表现的更多信息，但这并不容易。

### 练习5

确定以下哪个边界是紧密边界，哪些边界不是紧密边界。检查是否有界限可能是错误的。用o（符号）来说明不严密的边界。

1. 我们找到了一个O（n）上界的Θ（n）算法。
2. 我们找到了一个O（n 3）上界的Θ（n 2）算法。
3. 我们找到了一个O（n）上界的Θ（1）算法。
4. 我们找到一个O（1）上界的Θ（n）算法。
5. 我们找到了一个O（2n）上界的Θ（n）算法。

### 解

1. 在这种情况下，Θ复杂性和O复杂性是相同的，所以边界是紧密的。
2. 在这里，我们看到O复杂度比Θ复杂度更大，所以这个界限并不严密。事实上，O（n 2）的界限将是紧密的。所以我们可以写出该算法是o（n 3）。
3. 我们再次看到O复杂度比Θ复杂度更大，所以我们有一个不严密的界限。O（1）的边界将是一个紧的边界。所以我们可以指出，把O（n）写成O（n）并不严格。
4. 我们必须在计算这个界限时犯了一个错误，因为它是错误的。Θ（n）算法不可能具有O（1）的上界，因为n的复杂度大于1.请记住，O给出了一个上界。
5. 这可能看起来像一个不严密的界限，但事实并非如此。这个界限实际上很紧张。回想一下，2n和n的渐近行为是相同的，并且O和θ只与渐近行为有关。所以我们有O（2n）= O（n），因此这个界限是紧密的，因为复杂度与θ相同。

**经验法则**：计算算法的O复杂度比其Θ复杂度更容易。

到目前为止，您可能会对这些新的符号感到有些不知所措，但在我们介绍几个示例之前，我们先介绍另外两个符号。现在你很容易知道Θ，O和o，在本文中我们不会使用它们，但现在知道它们，现在我们已经知道了。在上面的例子中，我们修改了我们的程序以使其变得更糟（例如，获取更多指令并因此花费更多时间）并创建O符号。O是有意义的，因为它告诉我们我们的程序永远不会比特定的限制慢，所以它提供了有价值的信息，以便我们可以争辩说我们的程序足够好。如果我们做相反的事情并修改我们的计划以使其**更好**并找出结果程序的复杂性，我们使用符号Ω。因此，Ω给了我们复杂性，我们知道我们的程序不会比。如果我们想证明程序运行缓慢或算法不好，这非常有用。这可以用来论证算法在特定情况下运行速度太慢。例如，说算法是Ω（n 3）意味着该算法不比n 3好。它可能是Θ（n 3），与Θ（n 4）一样差，甚至更糟糕，但我们知道它至少有点不好。所以Ω为我们算法的复杂性提供了一个*下界*。类似于ο，如果我们知道我们的边界不紧，我们可以写ω。例如，一个Θ（n 3）算法是ο（n 4）和ω（n 2）。Ω（n）发音为“n的大ω”，而ω（n）发音为“n的小ω”。

### 练习6

对于下面的Θ复杂性，写下一个紧密的和非紧密的O界限，以及一个紧密且非紧密的Ω界限，只要它们存在。

1. Θ（1）
2. Θ（![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)）
3. Θ（n）
4. Θ（n 2）
5. Θ（n 3）

### 解

这是上述定义的直接应用。

1. 紧密的边界将是O（1）和Ω（1）。一个不紧密的O-bound将是O（n）。回想一下，O给了我们一个上限。由于n大于1，这是一个非严格的限制，我们也可以把它写成o（n）。但是我们找不到Ω的非严格界限，因为对于这些函数我们不能低于1。所以我们必须处理严格的限制。
2. 紧密的边界必须与Θ的复杂度相同，因此它们分别是O（![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)）和Ω（![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)）。对于非紧边界，我们可以有O（n），因为n大于![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)，所以它是一个上界![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)。正如我们所知，这是一个不紧密的上界，我们也可以把它写成o（n）。对于不太紧的下限，我们可以简单地使用Ω（1）。由于我们知道这个界限并不严密，我们也可以把它写成ω（1）。
3. 紧密的边界是O（n）和Ω（n）。两个非紧密边界可以是ω（1）和o（n 3）。这些实际上是非常不好的界限，因为它们远不是最初的复杂性，但它们仍然使用我们的定义是有效的。
4. 紧密的边界是O（n 2）和Ω（n 2）。对于非紧密边界，我们可以再次使用ω（1）和o（n 3），如前面的例子。
5. 严格界限分别为O（n 3）和Ω（n 3）。两个非紧密边界可以是ω（![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)n 2）和o（![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)n 3）。尽管这些边界并不严密，但它们比我们上面给出的要好。

我们使用O和Ω代替Θ，尽管O和Ω也可以给出一个紧密的界限，因为我们可能无法判断我们发现的界限是否紧张，或者我们可能不想经历过程仔细检查它。

如果你没有完全记住所有不同的符号及其用途，现在不要担心它太多。你总是可以回来看看它们。最重要的符号是O和Θ。

还要注意的是，尽管Ω为我们的函数提供了一个下界行为（即我们已经改进了我们的程序并使其执行的指令较少），但我们仍然指的是“最坏情况”分析。这是因为我们正在为给定n提供最糟糕的可能输入，并在此假设下分析它的行为。

下表显示了我们刚刚介绍的符号以及它们与通常用于数字的比较数学符号的对应关系。我们在这里不使用通常的符号并使用希腊字母代替的原因是指出我们正在做一个渐近行为比较，而不仅仅是一个简单的比较。

| 渐近比较算子              | 数字比较运算符            |
| ------------------------- | ------------------------- |
| 我们的算法是**o**（某事） | 一个数字是**<** something |
| 我们的算法是**O**（某物） | 一个数字是**≤的**东西     |
| 我们的算法是**Θ**（某物） | 数字是**=**某事           |
| 我们的算法是**Ω**（某物） | 一个数字是**≥的**东西     |
| 我们的算法是**ω**（某物） | 一个数字**>**某事         |

**经验法则**：尽管所有符号O，O，Ω，ω和Θ都有用，但O更常用，因为它比Θ更容易确定，并且比Ω更有用。

![对数函数远低于平方根函数，即使对于小的n，它也比线性函数低得多](http://discrete.gr/complexity/images/log-vs-linear.png)**图4**：函数n ![sqrt（n）](http://discrete.gr/complexity/images/sqrtn.png)，和log（n）的比较。函数n，在顶部以绿色绘制的线性函数增长得比平方根函数快得多，在中间以红色绘制，反过来，其增长速度比在（蓝色）绘制的log（n）函数快得多这个阴谋的底部。即使对于像n = 100这样的小n，其差别也是相当明显的。

## 对数

如果您知道什么对数，请随意跳过本节。由于很多人对对数不熟悉，或者最近没有使用过它们，也不记得它们，所以本节作为对它们的介绍。本文也适用于在学校还没有看到对数的年轻学生。对数很重要，因为它们在分析复杂性时会发生很多。阿*对数*是施加到一个数，使得它相当小的操作-很像一个数的平方根。所以如果有一件事你想记住关于对数的是他们需要一个数字并且使它比原来小得多（参见**图4**）。现在，就像平方根是平方的逆运算一样，对数是指数化的逆运算。这听起来并不难。最好用一个例子来解释。考虑以下等式：

2 x = 1024

我们现在希望为x解出这个方程。所以我们问自己：我们必须提高基数2以便得到1024的数量是多少？这个数字是10.的确，我们有2 10 = 1024，这很容易验证。对数可以帮助我们用新的符号表示这个问题。在这种情况下，10是1024的对数，我们将其写为log（1024），并将其读为“1024的对数”。因为我们使用2作为基数，所以这些对数称为基数2对数。其他基数有对数，但本文只使用基数2的对数。如果你是一名参加国际比赛的学生，并且你不了解对数，我强烈建议你[练习你的对数](http://tutorial.math.lamar.edu/Classes/Alg/LogFunctions.aspx)完成这篇文章后。在计算机科学中，基数2的对数比任何其他类型的对数要普遍得多。这是因为我们通常只有两个不同的实体：0和1.我们也倾向于将一个大问题分成两半，其中总有两个。所以你只需要知道基数2的对数就可以继续这篇文章。

### 习题7

解下面的等式。表示你在每种情况下找到的对数。仅使用对数2。

1. 2 x = 64
2. （2 2）x = 64
3. 4 x = 4
4. 2 x = 1
5. 2 x + 2 x = 32
6. （2 ×）×（2 ×）= 64

### 解

除了应用上面定义的想法之外，没有什么更多。

1. 通过反复试验，我们可以发现x = 6，所以log（64）= 6。
2. 这里我们注意到（2 2）x由指数的性质可以写成2 2x。所以我们有2x = 6，因为前一个结果的log（64）= 6，因此x = 3。
3. 利用我们先前方程中的知识，我们可以将4写成2 2，所以我们的方程变成（2 2）x = 4，这与2 2x = 4 相同。然后我们注意到log（4）= 2，因为2 2 = 4，因此我们有2x = 2。因此x = 1。这很容易从原始方程中观察到，因为使用1的指数会得出基数。
4. 回想一下，0的指数产生1的结果。所以我们有log（1）= 0，因为2 0 = 1，所以x = 0。
5. 这里我们有一个和，所以我们不能直接取对数。但是我们注意到2 x + 2 x与2 *（2 x）相同。所以我们又乘以另外两个，因此这与2 x + 1相同，现在我们所要做的就是求解方程2 x + 1 = 32。我们发现log（32）= 5等等x + 1 = 5，因此x = 4。
6. 我们将两个幂乘以2，所以我们可以通过注意到（2 x）*（2 x）与2 2x相同。那么我们需要做的就是求解方程2 2x = 64，我们已经在上面解决了，所以x = 3。

**经验法则**：对于用C ++实现的竞争算法，一旦你分析了你的复杂性，你可以粗略估计你的程序运行的速度，期望它每秒执行大约1,000,000次操作，通过描述你的算法的渐近行为函数。例如，一个Θ（n）算法花费大约一秒来处理n = 1,000,000的输入。

![阶乘（5） - >阶乘（4） - >阶乘（3） - >阶乘（2） - >阶乘（1）](http://discrete.gr/complexity/images/factorial-recursion.png)**图5**：阶乘函数执行的递归。

## 递归复杂性

现在我们来看一个递归函数。一个*递归函数*是调用自身的函数。我们可以分析其复杂性吗？以Python编写的以下函数评估给定数字的[阶乘](http://en.wikipedia.org/wiki/Factorial)。一个正整数的阶乘是通过将它与所有以前的正整数相乘而得到的。例如，5的阶乘是5 * 4 * 3 * 2 * 1。我们表示“5！” 并发音为“五阶乘积”（有些人更喜欢用“FIVE !!!”大声尖叫它发音）

`def` `factorial( n ):`

`if` `n ``=``=` `1``:`

`return` `1`

`return` `n ``*` `factorial( n ``-` `1` `)`

让我们分析一下这个函数的复杂性。这个函数没有任何循环，但其复杂性也不是常量。我们需要做的就是找出它的复杂性，然后再去计算指令。显然，如果我们将n传递给这个函数，它会执行n次。如果你对此不确定，现在运行n = 5来验证它是否真正起作用。例如，对于n = 5，它将执行5次，因为它会在每次调用中将n减1。因此我们可以看到这个函数是Θ（n）。

如果您不确定这一事实，请记住，您始终可以通过计算指令来查找确切的复杂性。如果你愿意，你现在可以尝试计算由这个函数执行的实际指令来找到一个函数f（n）并且看到它确实是线性的（记得线性的意思是Θ（n））。

请参**见图5**的图表，以帮助您了解调用阶乘（5）时执行的递归。

这应该清楚为什么这个函数是线性复杂的。

![在数组中进行二进制搜索](http://discrete.gr/complexity/images/binary-search.png)**图6**：二分搜索执行的递归。每个呼叫的A参数以黑色突出显示。递归继续，直到被检查的数组只包含一个元素。致谢Luke Francl。

## 对数复杂度

计算机科学中的一个着名问题是在数组内搜索一个值。我们早些时候为一般情况解决了这个问题。如果我们有一个已排序的数组并且我们想要在其中找到给定值，那么这个问题就变得有趣了。一种方法就是*二进制搜索*。我们看看我们数组的中间元素：如果我们发现它，我们就完成了。否则，如果我们发现的值比我们要查找的值大，我们知道我们的元素将位于数组的左边。否则，我们知道它将在数组的右侧。我们可以继续将这些较小的阵列切成两半，直到我们有一个单独的元素可以查看。这里是使用伪代码的方法：

`def` `binarySearch( A, n, value ):`

`if` `n ``=` `1``:`

`if` `A[ ``0` `] ``=` `value:`

`return` `true`

`else``:`

`return` `false`

`if` `value < A[ n ``/` `2` `]:`

`return` `binarySearch( A[ ``0.``..( n ``/` `2` `-` `1` `) ], n ``/` `2` `-` `1``, value )`

`else` `if` `value > A[ n ``/` `2` `]:`

`return` `binarySearch( A[ ( n ``/` `2` `+` `1` `)...n ], n ``/` `2` `-` `1``, value )`

`else``:`

`return` `true`

这个伪代码是实际实现的简化。在实践中，这种方法比实现更容易描述，因为程序员需要处理一些实现问题。有错误的错误，除以2可能不总是产生一个整数值，所以有必要floor（）或ceil（）该值。但是，我们可以为我们的目的假设它会一直成功，并且我们会假设我们的实际实施实际上处理了错误的错误，因为我们只想分析这种方法的复杂性。如果你以前从未实现过二分搜索，那么你可能希望用你最喜欢的编程语言来做这件事。这是一个真正的启发性努力。

请参阅**图6**以帮助您了解二分法搜索的运作方式。

如果您不确定此方法是否有效，请立即花一点时间用一个简单的示例手动运行它，并说服自己确实可行。

现在让我们尝试分析这个算法。同样，在这种情况下我们有一个递归算法。为简单起见，我们假设数组总是被精简为一半，而忽略递归调用中的+1和-1部分。现在你应该确信，一点点改变，比如忽略+ 1和-1不会影响我们的复杂性结果。这是一个事实，我们通常必须证明我们是否希望从数学的角度来看是谨慎的，但实际上它是直观明显的。为了简单起见，我们假设我们的数组的大小精确到2。这个假设再一次不会改变我们将要到达的复杂性的最终结果。对于这个问题，最糟糕的情况会发生在我们要查找的值完全不在我们的数组中。在那种情况下，d在递归的第一次调用中从一个大小为n的数组开始，然后在下一次调用中获得大小为n / 2的数组。然后我们会在下一次递归调用中得到一个大小为n / 4的数组，然后是一个大小为n / 8的数组，等等。一般来说，我们的数组在每次调用时都会被分成两半，直到达到1.所以，让我们在每次调用时都写入数组中的元素数量：

1. 第 0 次迭代：n
2. 第一次迭代：n / 2
3. 2 次迭代：N / 4
4. 第3 次迭代：n / 8
5. ...
6. 第 i 次迭代：n / 2 i
7. ...
8. 最后一次迭代：1

请注意，在第i次迭代中，我们的数组有n / 2个i元素。这是因为在每次迭代中我们都将我们的数组减半，这意味着我们将其元素数量除以2。这意味着将分母乘以2.如果我们这样做，我们得到n / 2 i。现在，这个过程继续下去，每增加一个，我们就会得到更少的元素，直到我们到达最后一次迭代时，我们只剩下1个元素。如果我们希望找到我看到这将发生什么迭代，我们必须解出下面的等式：

1 = n / 2 i

当我们到达binarySearch（）函数的最终调用时，这只会是真的，而不是在一般情况下。所以在这里解决我将帮助我们找到递归在哪个迭代中完成。双方乘以2 我得到：

2 i = n

现在，如果你阅读上面的对数部分，这个方程应该看起来很熟悉。为我解决我们有：

i = log（n）

这告诉我们执行二进制搜索所需的迭代次数是log（n），其中n是原始数组中元素的数量。

如果你考虑一下，这是有道理的。例如，取n = 32，一个由32个元素组成的数组。我们有多少次需要减少一半才能获得1个元素？我们得到：32→16→8→4→2→1。我们做了5次，这是32的对数。因此，二进制搜索的复杂度是Θ（log（n））。

最后的结果使我们能够比较二分查找和线性查找，这是我们以前的方法。显然，由于log（n）比n小得多，所以有理由得出结论：二元搜索是一种在数组内进行搜索然后进行线性搜索的更快的方法，所以如果我们想要做的话保持数组的排序可能是明智的许多搜索内容。

**经验法则**：改善程序的渐近运行时间往往会大大提高其性能，远远超过任何较小的“技术”优化，如使用更快的编程语言。

## 最佳分拣

**恭喜。**您现在知道如何分析算法的复杂性，函数的渐近行为和大O符号。您还知道如何直观地发现算法的复杂性是O（1），O（log（n）），O（n），O（n 2）等等。您知道符号o，o，ω，Ω和Θ以及最坏情况分析的含义。如果你已经到了这里，本教程已经达到了它的目的。

最后一节是可选的。这是一个更多的参与，所以如果你感到不知所措，随意跳过它。这将需要您专注并花费一些时间来完成练习。但是，它将为您提供非常有用的算法复杂度分析方法，它非常强大，所以这当然值得理解。

我们查看了上面称为选择排序的排序实现。我们提到选择排序不是最优的。一个*最优算法*是解决的最好的方式有问题，这意味着这个问题没有更好的算法的算法。这意味着解决该问题的所有其他算法与该最优算法相比具有更差或相等的复杂性。对于一个共享相同复杂度的问题，可能有许多最优算法。排序问题可以通过各种方式得到最佳解决。我们可以使用与二进制搜索相同的想法快速排序。这种排序方法称为*mergesort*。

为了执行mergesort，我们首先需要构建一个帮助函数，然后我们将使用它来执行实际的排序。我们将创建一个`merge`函数，它接受两个已经排序的数组，并将它们合并为一个大的排序数组。这很容易完成：

`def` `merge( A, B ):`

`if` `empty( A ):`

`return` `B`

`if` `empty( B ):`

`return` `A`

`if` `A[ ``0` `] < B[ ``0` `]:`

`return` `concat( A[ ``0` `], merge( A[ ``1.``..A_n ], B ) )`

`else``:`

`return` `concat( B[ ``0` `], merge( A, B[ ``1.``..B_n ] ) )`

concat函数接受一个项目，“head”和一个数组，即“tail”，并建立并返回一个新的数组，其中包含给定的“head”项作为新数组中的第一件事物和给定的“tail “项作为数组中的其余元素。例如，concat（3，[4，5，6]）返回[3,4,5,6]。我们用A_n和B_n分别表示数组A和B的大小。

### 练习8

验证上面的函数实际执行合并。以迭代的方式（使用`for`循环）以您最喜欢的编程语言重写它，而不是使用递归。

分析这个算法表明它有一个运行时间Θ（n），其中n是结果数组的长度（n = A_n + B_n）。

### 习题9

验证运行时间`merge`是Θ（n）。

利用这个函数，我们可以构建一个更好的排序算法。这个想法如下：我们将数组分成两部分。我们对这两个部分分别进行递归排序，然后将两个排序后的数组合并成一个大数组。在伪代码中：

`def` `mergeSort( A, n ):`

`if` `n ``=` `1``:`

`return` `A ``# it is already sorted`

`middle ``=` `floor( n ``/` `2` `)`

`leftHalf ``=` `A[ ``1.``..middle ]`

`rightHalf ``=` `A[ ( middle ``+` `1` `)...n ]`

`return` `merge( mergeSort( leftHalf, middle ), mergeSort( rightHalf, n ``-` `middle ) )`

这个功能比我们以前经历的更难理解，所以下面的练习可能会花费你几分钟的时间。

### 练习10

验证的正确性`mergeSort`。也就是说，检查`mergeSort`上面定义的实际上是否正确地对它给出的数组进行排序。如果您无法理解其原理，请尝试使用一个小型示例数组并“手动”运行它。手动运行此功能时，确保左半部分和右半部分是您在中间切割阵列时所得到的结果; 如果数组有奇数个元素（这就是`floor`上面的用法），它并不一定在中间。

作为最后一个例子，让我们分析一下复杂性`mergeSort`。在每一个步骤中`mergeSort`，我们都将数组分成两半大小相同的数据，类似于`binarySearch`。但是，在这种情况下，我们在整个执行过程中保持两半。然后我们在每一半中递归地应用算法。递归返回后，我们`merge`对需要Θ（n）次的结果应用该操作。

所以，我们将原始数组分成两个大小为n / 2的数组。然后我们合并这些数组，这是一个合并n个元素的操作，因此需要Θ（n）个时间。

看看**图7**来理解这个递归。

![N分为N / 2和N / 2，其中每个分为N / 4和N / 4，并且该过程继续，直到我们调用大小为1的数据为止。](http://discrete.gr/complexity/images/mergesort-recursion.png)**图7**：合并排序的递归树。

让我们来看看这里发生了什么。每个圆圈表示对该`mergeSort`函数的调用。写在圆圈中的数字表示正在排序的数组的大小。最上面的蓝色圆圈是最初的调用`mergeSort`，我们可以在这里对大小为n的数组进行排序。箭头表示在函数之间进行递归调用。最初的调用在两个数组上`mergeSort`进行两次调用`mergeSort`，每个数组的大小为n / 2。这由顶部的两个箭头指示。反过来，这些调用中的每一个都会对`mergeSort`两个大小为n / 4的数组分别进行两次调用，等等，直到我们到达大小为1的数组。这个图称为*递归树*，因为它说明了递归如何表现看起来像一棵树（*根*在顶部，*叶子*在底部，所以实际上它看起来像一棵倒转的树）。

请注意，在上图中的每一行中，元素的总数是n。要看到这一点，请分别查看每一行。第一行只包含一个`mergeSort`大小为n的数组的调用，所以元素的总数是n。第二行有两个对`mergeSort`n / 2大小的调用。但是n / 2 + n / 2 = n，所以在这一行中元素的总数是n。在第三行中，我们有4个调用，每个调用应用于一个n / 4大小的数组，产生等于n / 4 + n / 4 + n / 4 + n / 4 = 4n / 4的元素总数= n。所以我们再次获得n个元素。现在注意，在这个图的每一行中，调用者必须执行一个`merge`对被调用者返回的元素进行操作。例如，用红色表示的圆圈必须对n / 2个元素进行排序。要做到这一点，它会将n / 2大小的数组分割成两个n / 4大小的数组，调用`mergeSort`递归来对这些数组进行排序（这些调用是用绿色指示的圆圈），然后将它们合并到一起。此合并操作需要合并n / 2个元素。在我们的树的每一行中，合并元素的总数是n。在我们刚刚探索的那一行中，我们的函数合并了n / 2个元素，而其右侧的函数（它是蓝色的）也必须合并它自己的n / 2个元素。这总共产生了n个元素，需要为我们正在查看的行进行合并。

通过这个参数，每行的复杂度是Θ（n）。我们知道这个图中的行数（也称为递归树的*深度）*将是log（n）。这个推理与我们在分析二进制搜索复杂性时使用的推理完全相同。我们有log（n）行，每个行都是Θ（n），因此复杂度`mergeSort`为Θ（n * log（n））。这比选择排序给予我们的Θ（n 2）要好得多（记住log（n）远小于n，所以n * log（n）远小于n * n = n 2）。如果这听起来很复杂，不要担心：第一次看到它并不容易。在您最喜欢的编程语言中实现mergesort并验证它是否有效后，重新访问此部分并重新阅读这里的参数。

正如您在最后一个例子中看到的那样，复杂性分析允许我们比较算法以查看哪一个更好。在这种情况下，我们现在可以非常确定合并排序将优于大数组的选择排序。如果我们没有我们开发的算法分析的理论背景，这个结论很难画出来。实际上，确实使用运行时间Θ（n * log（n））的排序算法。例如，[Linux内核使用称为heapsort的排序算法](http://lxr.free-electrons.com/source/lib/sort.c)，它的运行时间与我们在这里探索的mergesort相同，即Θ（n log（n）），因此是最优的。注意我们还没有证明这些排序算法是最优的。要做到这一点需要稍微涉及一些数学论证，但请放心，从复杂性的角度来看，它们不会变得更好。

阅读本教程后，您为算法复杂性分析开发的直觉应该能够帮助您设计更快的程序，并将优化工作集中在那些非常重要的事情上，而不是那些无关紧要的小事情，让您的工作更有成效。此外，本文中开发的数学语言和符号（例如big-O符号）有助于与其他软件工程师进行交流，以便争论算法的运行时间，因此希望您可以用新的方法进行操作获得的知识。

## 关于

本文是根据[知识共享3.0署名](http://creativecommons.org/licenses/by/3.0/)授权的。这意味着您可以复制/粘贴，分享，将其发布到您自己的网站上，更改它，并且通常按照您的意愿做任何事情，并提供您的名字。虽然你不必，但如果你将自己的作品建立在我的基础上，我鼓励你在Creative Commons下发表你自己的作品，这样其他人也可以更容易地分享和合作。以类似的方式，我必须认定我在这里使用的工作。您在此页面上看到的漂亮图标是[神游图标](http://p.yusukekamiyamane.com/)。你在这个设计中看到的漂亮的条纹图案是由[Lea Verou](http://leaverou.me/css3patterns/)创建的。而且，更重要的是，我认识的这些算法能够写出这篇文章，这些都是我的教授教给我的[Nikos Papaspyrou](http://www.softlab.ntua.gr/~nickie/)和[Dimitris ](http://www.softlab.ntua.gr/~fotakis/)[Fotakis](http://www.softlab.ntua.gr/~nickie/)。

我目前是[雅典大学的](http://di.uoa.gr/)密码学博士候选人。当我写这篇文章，我是一名大学生[电子与计算机工程](http://ece.ntua.gr/)的本科[雅典国家技术大学](http://ntua.gr/)掌握的[软件](http://www.cslab.ntua.gr/)，并在教练[的信息学竞赛的希腊](http://pdp.gr/)。在行业方面，我曾经是一个工程团队的成员，他在[Google](https://www.google.com/)和[Twitter](https://twitter.com/)的安全团队以及两个初创公司Zino和Kamibu 为艺术家建立了一个社交网络[deviantART](http://www.deviantart.com/)，在那里我们进行社交网络和视频游戏发展。[在Twitter](http://www.twitter.com/dionyziz)或[GitHub上](http://github.com/dionyziz)[关注我](http://www.twitter.com/dionyziz)如果你喜欢这个，或者[给我发邮件，](mailto:dionyziz@gmail.com)如果你想联系。许多年轻的程序员对英语语言并不熟悉。如果您想将本文翻译成您自己的母语，请发邮件给我，以便更多人可以阅读。

**谢谢阅读。**我没有得到报酬写这篇文章，所以如果你喜欢它，[给我发一封电子邮件](mailto:dionyziz@gmail.com)打个招呼。我喜欢接收世界各地的照片，所以请随时在自己的城市中贴上自己的照片！

## 参考

1. Cormen，Leiserson，Rivest，Stein。[算法介绍](http://www.amazon.co.uk/Introduction-Algorithms-T-Cormen/dp/0262533057/ref=sr_1_1?ie=UTF8&qid=1341414466&sr=8-1)，麻省理工学院出版社。
2. Dasgupta，Papadimitriou，Vazirani。[算法](http://www.amazon.co.uk/Algorithms-Sanjoy-Dasgupta/dp/0073523402/ref=sr_1_1?s=books&ie=UTF8&qid=1341414505&sr=1-1)，麦格劳 - 希尔出版社。
3. Fotakis。雅典国立技术大学[离散数学](http://discrete.gr/)课程。
4. Fotakis。雅典国立技术大学[算法与复杂性](http://www.corelab.ece.ntua.gr/courses/algorithms/)课程。